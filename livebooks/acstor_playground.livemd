# ACStor Playground

## Introduction

This livebook is used to play as REPL for developing ACStor Scenario.
So, start workflow_umbrella project and connect to it as attached node.

```elixir
# Test to see if we could get auth token from workflow_umbrella project.
alias Azure.Auth
Auth.get_auth_token(Auth.azure_scope())
```

<!-- livebook:{"branch_parent_index":0} -->

## Test log to a local file

```elixir
alias Steps.Exec
```

```elixir
Steps.Common.Time.get_time_millisecond()
```

```elixir
log_file = Steps.LogBackend.create_tmp_log_file("playground.txt")
```

```elixir
Exec.run(%{cmd: "ls -la", log_file: log_file})
```

```elixir
Exec.run(%{cmd: "ls filenotexist", log_file: log_file})
```

<!-- livebook:{"branch_parent_index":0} -->

## Test replication steps and log to a file

```elixir
alias Steps.Acstor.Replication, as: Rep
```

```elixir
log_file = Steps.LogBackend.create_tmp_log_file("replication.txt")
```

```elixir
settings = %{
  sub: "65490f91-f2c2-4514-80ba-4ec1de89aeda",
  region: "eastus",
  rg: "acstor-replication-test",
  session_dir: "/tmp/logs/2023-8-26/az_cli_sessions/lot2mn"
}
```

```elixir
settings |> Rep.az_set_subscription()
```

<!-- livebook:{"branch_parent_index":0} -->

## How to use Worker to execute ACStor replication

* For one scenario such as managed disk, `Worker.Leader` load different settings from a scenario setting service. Such as number of disks, run time. 
  The purpose of this is to generate different settings for each workflow later to use.

* `Worker.Leader` specify how many `Worker` are created. There could be `M` workers for `N` workflows.

* For replication, when `Worker.Leader` assign workflow to `worker`, it need to reset worker's some interal state (such as: AKS cluster name)

* A `Worker` use inital settings got from `Worker.Leader` to run workflow by execute each steps in the workflow.

* After each step is execute by a `Worker`, the state of the `Worker` need to be updated by that step.

Each step is a pure function from Steps.Acstor.Replication module.

* We update a `Worker`'s state by wrapping the pure function in another function.

**Update**

* `Worker` no longer execute workflows, it doesn't know about workflows.
* `Worker` only care about executing a step.
* The concept of workflow which is the sequence of steps is kept only in `Worker.Leader`.

## Scenario Settings

```elixir
symbol = "azure_disk_replication"
```

<!-- livebook:{"branch_parent_index":4} -->

## Test 1.1: start scenario

```elixir
# Stop a scenario
Workflow.stop_scenario(symbol)
```

```elixir
Kino.Process.render_sup_tree(DynamicSymbolSupervisor)
```

```elixir
# Start a scenario
Workflow.start_scenario(symbol)
```

<!-- livebook:{"branch_parent_index":4} -->

## (optional) run one step for dev

```elixir
# If there is one worker, then we could test one step 
# by simply schedule a workload containing one step
# Create a workflow which only has one symbol 
%{
  symbol: symbol,
  workflow_definition: [{"Steps.Acstor.Replication", "check_labeled_noded"}]
}
|> Worker.Leader.add_workflow_for_symbol()

# schedule the workflow to a worker (now, there is only one worker)
Worker.Leader.schedule_workflows(symbol)

# Trigger the workflows assigned to workers
Worker.Leader.execute_workflows_for_symbol(symbol)
```

<!-- livebook:{"branch_parent_index":4} -->

## (optinal) check the worker state

```elixir
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")

state = Worker.worker_state(worker_pid)
state.history
```

```elixir
state.step_context
```

<!-- livebook:{"branch_parent_index":4} -->

## (optinal) check leader state

```elixir
Worker.Leader.leader_state(symbol)
```

<!-- livebook:{"branch_parent_index":4} -->

## (optional) add extra context to worker

```elixir
# Add extra context 
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")

if Process.alive?(worker_pid) do
  # check worker context
  Worker.add_worker_context(worker_pid, %{disk_type: "azure_disk"})
end
```

## (optional) cancel workflow from worker

```elixir
Worker.Leader.cancel_workflow(%{symbol: symbol, worker_name: "worker1"})
```

<!-- livebook:{"branch_parent_index":4} -->

## Test 1.2 Run workflow steps one by one

#### Add one workflow definition for a symbol

```elixir
workflow_definition =
  [
    "az_login_using_sp",
    "az_set_subscription",
    "az_create_resource_group",
    "az_create_aks_cluster",
    "az_add_node_pool"
  ]
  |> Enum.map(fn each -> {"Steps.Acstor.Replication", each} end)
```

```elixir
%{
  symbol: symbol,
  workflow_definition: workflow_definition
}
|> Worker.Leader.add_workflow_for_symbol()
```

#### Schedule workflows in Leader based on its current state

```elixir
Worker.Leader.schedule_workflows(symbol)
```

#### Trigger Leader to let each worker to run ONE step from its assigned workflow

```elixir
Worker.Leader.execute_workflows_for_symbol(symbol)
```

<!-- livebook:{"branch_parent_index":4} -->

## Test 4: execute one step with error

```elixir
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")

Worker.run_step(%{
  worker_pid: worker_pid,
  module_name: "Steps.Acstor.Replication",
  step_name: "dummy_step_will_fail"
})
```

The `reason` is a tuple with two parts:

* The first part: `:badmatch` indicate the error type and `{:err, "ls: cannot access 'non_exist_file': No such file or directory\n"}` shows reason for the error type.
* The second part shows the stacktrace.

<!-- livebook:{"break_markdown":true} -->

For example, if the step we execute list some file doesn't exist. We could catch the error in callback

<!-- livebook:{"force_markdown":true} -->

```elixir
@impl true
def terminate(reason, %{step_context: context} = _state) do
  reason |> IO.inspect(label: "#{__MODULE__} 64")
  context |> IO.inspect(label: "#{__MODULE__} 65")

  :normal
end
```

<!-- livebook:{"break_markdown":true} -->

The `reason` is

<!-- livebook:{"force_markdown":true} -->

```elixir
{
  {:badmatch, {:err, "ls: cannot access 'non_exist_file': No such file or directory\n"}},
  [
    {Steps.Acstor.Replication, :step_failed, 1,
      [file: 'lib/steps/acstor/replication.ex', line: 77]},
    {Worker, :handle_cast, 2, [file: 'lib/worker/worker.ex', line: 46]},
    {:gen_server, :try_dispatch, 4, [file: 'gen_server.erl', line: 1123]},
    {:gen_server, :handle_msg, 6, [file: 'gen_server.erl', line: 1200]},
    {:proc_lib, :init_p_do_apply, 3, [file: 'proc_lib.erl', line: 240]}
  ]
}
```

<!-- livebook:{"break_markdown":true} -->

The output on terminal shows the worker process has terminated.

```sh
[error] GenServer #PID<0.9844.0> terminating
** (MatchError) no match of right hand side value: {:err, "ls: cannot access 'non_exist_file': No such file or directory\n"}
    (workflow 0.1.0) lib/steps/acstor/replication.ex:77: Steps.Acstor.Replication.step_failed/1
    (workflow 0.1.0) lib/worker/worker.ex:46: Worker.handle_cast/2
    (stdlib 4.3) gen_server.erl:1123: :gen_server.try_dispatch/4
    (stdlib 4.3) gen_server.erl:1200: :gen_server.handle_msg/6
    (stdlib 4.3) proc_lib.erl:240: :proc_lib.init_p_do_apply/3
Last message: {:"$gen_cast", {:run_step, "Steps.Acstor.Replication", "step_failed"}}
State: %Worker.State{symbol: "azure_disk_replication", status: :ready, report_to: #PID<0.9843.0>, history: [{"Steps.Acstor.Replication", "az_set_subscription"}, {"Steps.Acstor.Replication", "az_login_using_sp"}], step_context: %{region: "eastus", rg: "acstor-replication-test", session_dir: "/tmp/logs/2023-8-27/az_cli_sessions/2bc5oj", sub: "65490f91-f2c2-4514-80ba-4ec1de89aeda"}}
```

<!-- livebook:{"break_markdown":true} -->

So, we need to save our state to leader in the callback.

<!-- livebook:{"branch_parent_index":4} -->

## Tmp

```elixir
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")

state = Worker.worker_state(worker_pid)

state.step_context
|> Steps.Acstor.Replication.label_nodes_with_tags()
```

```elixir
Steps.Acstor.Replication.get_random_pvc_name()
```
