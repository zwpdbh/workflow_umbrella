# ACStor Playground

## Introduction

This livebook is used to play as REPL for developing ACStor Scenario.
So, start workflow_umbrella project and connect to it as attached node.

```elixir
# Test to see if we could get auth token from workflow_umbrella project.
alias Azure.Auth
Auth.get_auth_token(Auth.azure_scope())
```

* For one scenario such as managed disk, `Worker.Leader` load different settings from a scenario setting service. Such as number of disks, run time. 
  The purpose of this is to generate different settings for each workflow later to use.

* `Worker.Leader` specify how many `Worker` are created. There could be `M` workers for `N` workflows.

* For replication, when `Worker.Leader` assign workflow to `worker`, it need to reset worker's some interal state (such as: AKS cluster name)

* A `Worker` use inital settings got from `Worker.Leader` to run workflow by execute each steps in the workflow.

* After each step is execute by a `Worker`, the state of the `Worker` need to be updated by that step.

Each step is a pure function from Steps.Acstor.Replication module.

* We update a `Worker`'s state by wrapping the pure function in another function.

**Update**

* `Worker` no longer execute workflows, it doesn't know about workflows.
* `Worker` only care about executing a step.
* The concept of workflow which is the sequence of steps is kept only in `Worker.Leader`.

## Scenario Settings

```elixir
symbol = "azure_disk_replication"
```

```elixir
Workflow.stop_scenario(symbol)
Workflow.start_scenario(symbol)
```

<!-- livebook:{"branch_parent_index":1} -->

## Execute replication workflow

```elixir
alias Worker.Leader
alias Steps.Acstor.WorkflowConfig

Kino.Process.render_sup_tree(DynamicSymbolSupervisor)
```

```elixir
# Add workflow to scenario 
azure_disk_workflow_definition =
  WorkflowConfig.azure_disk_replication()
  |> Enum.map(fn function_name ->
    {"Steps.Acstor.Replication", function_name}
  end)

Leader.add_workflows_for_symbol(%{
  symbol: symbol,
  workflows_definition: [
    azure_disk_workflow_definition
  ]
})
```

```elixir
Leader.schedule_workflows(symbol)
```

```elixir
Leader.execute_workflows_for_symbol(symbol)
```

```elixir
Leader.current_state(symbol)
|> Map.get(:workflows_finished)
|> Enum.map(fn x -> {x.workflow_id, x.workflow_status} end)
```

<!-- livebook:{"branch_parent_index":1} -->

## Execute arbitary kubectl command

```elixir
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")
state = Worker.worker_state(worker_pid)

state.step_context
|> Map.merge(%{})
|> Steps.Acstor.Replication.test_kubectl_cmd("kubectl get pods")
```

<!-- livebook:{"branch_parent_index":1} -->

## Execute arbitary az command

```elixir
{:ok, worker_pid} = Worker.Leader.get_worker_by_name(symbol, "worker1")
state = Worker.worker_state(worker_pid)

state.step_context
|> Map.merge(%{})
|> Steps.Acstor.Replication.test_az_cmd(
  "az group delete --name acstorbyzhaowei-nd19t2 --yes --no-wait"
)
```

## Simulate multiple workflow running

```elixir
# Settings 
symbol = "nvme"
```

<!-- livebook:{"branch_parent_index":5} -->

## Control Scneario execution

```elixir
Workflow.stop_scenario(symbol)
```

```elixir
Workflow.start_scenario(symbol)
```

```elixir
Kino.Process.render_sup_tree(DynamicSymbolSupervisor)
```

<!-- livebook:{"branch_parent_index":5} -->

## Control Leader

```elixir
alias Worker.Leader
alias Steps.Acstor.WorkflowConfig
```

```elixir
Leader.toggle_symbol_execution(symbol)
```

```elixir
workflow_definitions =
  1..2
  |> Enum.to_list()
  |> Enum.map(fn _ ->
    WorkflowConfig.dummy_workflow()
  end)

Leader.add_workflows_for_symbol(%{
  symbol: symbol,
  workflows_definition: workflow_definitions
})

# Leader.add_new_worker(symbol)
```

```elixir
Leader.current_state(symbol)
```

```elixir
Leader.schedule_workflows(symbol)
```

```elixir
Leader.execute_workflows_for_symbol(symbol)
```

```elixir
Leader.current_state(symbol)
|> Map.get(:workflows_finished)
|> Enum.map(fn x -> {x.workflow_id, x.workflow_status} end)
```
